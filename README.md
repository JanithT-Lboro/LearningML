# LearningML
A documentation of my route in learning ML  
  
Below is a list of the resources that I have used or referred to:  
- [How to Learn Machine Learning](https://elitedatascience.com/learn-machine-learning)
- [Pattern Recognition by SERGIOS THEODORIDIS and KONSTANTINOS KOUTROUMBAS](https://github.com/JanThan/LearningML/blob/master/PatternRecognition.pdf)

First, I fully completed Andrew Ng's very indepth [course](https://www.coursera.org/learn/machine-learning) on coursera. 
Whilst old, it still seems to cover the fundamentals very well. The assignments I completed as part of this course can be found [linked](https://github.com/JanThan/LearningML/tree/master/AndrewNg_MLCourse).  

I have since begun working through the following individual projects, to further solidify what I have learnt from the course.  
- [Iris Flowers Classification ML Project](https://github.com/JanThan/LearningML/tree/master/IRIS)
- [Boston Housing Prices Estimate Project](https://github.com/JanThan/LearningML/tree/master/BostonHousingProblem)
- [Compressive Strength of Concrete](https://github.com/JanThan/LearningML/tree/master/CompressiveStrengthOfConcrete)

As part of this process, I will also need to be able to implement the following algorithms from scratch on more simple datasets to also gain a better understanding of how particular algorithms work. In the interest of saving time, I will in most cases be randomly generating datasets to use.
- [Linear regression](https://github.com/JanThan/LearningML/tree/master/AlgorithmImplementations/LinearRegression)
- Logistic regression
- Descision tree
- SVM (support vector machine)
- Naive Bayes
- [KNN (K-Nearest Neighbours)](https://github.com/JanThan/LearningML/tree/master/AlgorithmImplementations/KNN)
- K-Means
- Random Forest
- Dimensionality Reduction Algorithms
- Gradient Boosting and AdaBoost
By implementing them at the most basic level, I will be able to gain a greater appreciation for their stengths and limitations. 
